<div align="center">
  <img src="src/smart_watch/assets/images/logo_app.jpg" alt="Logo SmartWatch" />
</div>

# SmartWatch : Extracteur d'Horaires Intelligent

**SmartWatch** est un pipeline de donn√©es complet con√ßu pour extraire, analyser, et comparer les horaires d'ouverture de divers √©tablissements (mairies, piscines, m√©diath√®ques) √† partir de leurs sites web. Il utilise des mod√®les de langage pour interpr√©ter le contenu et le comparer √† des donn√©es de r√©f√©rence, puis g√©n√®re et envoie par mail des rapports HTML interactifs pour visualiser les r√©sultats.

## ‚ú® Fonctionnalit√©s

*   **Collecte de Donn√©es** : Charge les URLs des √©tablissements √† analyser depuis un fichier CSV.
*   **Conversion des Donn√©es** : Converti les pages web en Markdown et nettoie ce dernier pour ne garder que l'essentiel
*   **Filtrage de Contenu Intelligent** : Utilise des embeddings (via `nomic-embed`) pour identifier et extraire uniquement les sections de page web pertinentes aux horaires, optimisant ainsi les appels aux LLM.
*   **Extraction par LLM** : Interroge des LLM (compatibles OpenAI ou Mistral) pour extraire les horaires dans un format structur√© customis√© (JSON).
*   **Conversion des horaires** : Le format JSON customis√© est converti au format OSM.
*   **Comparaison Automatis√©e** : Compare les horaires extraits par le LLM avec des donn√©es de r√©f√©rence (depuis data.grandlyon.com) pour d√©tecter les divergences.
*   **Rapports D√©taill√©s** : G√©n√®re des rapports HTML interactifs et un r√©sum√© simple, permettant de visualiser les statistiques globales, les statuts de traitement, et les d√©tails de chaque URL.
*   **Notifications** : Envoie automatiquement les rapports par email.
*   **Orchestration Robuste** : Un pipeline assure une ex√©cution s√©quentielle et contr√¥l√©e.
*   **Conteneurisation** : Pr√™t √† l'emploi avec Docker et Docker Compose pour un d√©ploiement simplifi√©.

## Diagramme
```
[ main.py ] (Orchestrateur du Pipeline)
     ‚îÇ
     ‚îú‚îÄ> 1. Initialise [ core.ConfigManager ] (Charge la configuration depuis .env)
     ‚îÇ         ‚îî‚îÄ> Agr√®ge [ config.* ] (LLMConfig, DatabaseConfig, etc.)
     ‚îÇ
     ‚îú‚îÄ> 2. Initialise les processeurs principaux avec la configuration
     ‚îÇ
     ‚îî‚îÄ> 3. Ex√©cute le pipeline s√©quentiel :
         ‚îÇ
         ‚îú‚îÄ> [A] SETUP : [ utils.CSVToPolars ] -> [ processing.DatabaseManager ]
         ‚îÇ     (Charge les URLs depuis le CSV et pr√©pare une nouvelle ex√©cution en base)
         ‚îÇ
         ‚îú‚îÄ> [B] FETCH : [ processing.URLProcessor ]
         ‚îÇ     (R√©cup√®re le contenu des URLs)
         ‚îÇ     ‚îî‚îÄ> Utilise [ utils.HtmlToMarkdown ] pour la conversion
         ‚îÇ
         ‚îú‚îÄ> [C] CLEAN : [ utils.MarkdownCleaner ]
         ‚îÇ     (Nettoie le Markdown brut)
         ‚îÇ
         ‚îú‚îÄ> [D] FILTER : [ core.MarkdownProcessor ]
         ‚îÇ     (Filtre s√©mantiquement le Markdown pour ne garder que les sections pertinentes)
         ‚îÇ     ‚îî‚îÄ> Utilise [ core.LLMClient ] pour les embeddings (ex: nomic-embed-text)
         ‚îÇ
         ‚îú‚îÄ> [E] EXTRACT : [ processing.LLMProcessor ]
         ‚îÇ     (Extrait les horaires du Markdown filtr√© au format JSON)
         ‚îÇ     ‚îú‚îÄ> Utilise [ core.LLMClient ] pour l'appel au LLM (ex: OpenAI, Mistral)
         ‚îÇ     ‚îî‚îÄ> Utilise [ utils.CustomJsonToOSM ] pour convertir le JSON en format OSM
         ‚îÇ
         ‚îú‚îÄ> [F] COMPARE : [ processing.ComparisonProcessor ]
         ‚îÇ     (Compare les horaires extraits (OSM) avec les donn√©es de r√©f√©rence)
         ‚îÇ     ‚îî‚îÄ> Utilise [ core.ComparateurHoraires ] pour la logique de comparaison
         ‚îÇ
         ‚îî‚îÄ> [G] REPORT : [ reporting.ReportManager ]
               (G√©n√®re et envoie le rapport final)
               ‚îú‚îÄ> Utilise [ reporting.GenererRapportHTML ] pour cr√©er le fichier HTML
               ‚îî‚îÄ> Utilise [ core.EmailSender ] pour envoyer l'email avec pi√®ces jointes

-----------------------------------------------------------------------------------------
Modules Transversaux (utilis√©s par de nombreux composants) :
-----------------------------------------------------------------------------------------
  - [ core.Logger ] : Utilis√© par tous les modules pour la journalisation.
  - [ core.ErrorHandler ] : Utilis√© pour une gestion centralis√©e des erreurs.
  - [ processing.DatabaseManager ] : Utilis√© par toutes les √©tapes du pipeline pour lire et √©crire les r√©sultats dans la base de donn√©es SQLite.
  - [ data_models.schema_bdd ] : D√©finit la structure de la base de donn√©es pour SQLAlchemy.
  ```

## üöÄ Installation

1.  **Clonez le d√©p√¥t :**
    ```sh
    git clone <url-du-repo>
    cd smart_watch
    ```

2.  **Cr√©ez un environnement virtuel et activez-le :**
    ```sh
    python -m venv .venv
    source .venv/bin/activate  # Sur Windows: .venv\Scripts\activate
    ```

3.  **Installez les d√©pendances :**
    ```sh
    pip install -r requirements.txt
    ```

## ‚öôÔ∏è Configuration

1.  Cr√©ez un fichier `.env` √† la racine du projet en vous basant sur le mod√®le [`env.model`](.env.model).
2.  Configurez les variables d'environnement requises :
    *   `CSV_URL_HORAIRES`: L'URL ou le chemin local du fichier CSV contenant les lieux √† analyser.
    *   **Configuration LLM** : Renseignez les cl√©s d'API et les mod√®les pour le fournisseur de votre choix (OpenAI, Mistral, etc.).
    *   **Configuration Email** : Param√©trez les informations SMTP pour l'envoi des rapports.

## ‚ñ∂Ô∏è Utilisation

Pour lancer le pipeline complet, ex√©cutez le script principal :

```sh
python main.py
```

Le programme effectuera les actions suivantes :
1.  Initialisera la base de donn√©es SQLite (`data/SmartWatch.db`).
2.  Traitera chaque URL, filtrera le contenu, et extraira les horaires via le LLM.
3.  Comparera les r√©sultats et stockera tout en base de donn√©es.
4.  Enverra un rapport par mail.
5.  √âcrira les logs dans `logs/SmartWatch.log`.

## üê≥ Utilisation avec Docker

Vous pouvez √©galement lancer l'application dans un conteneur Docker.

1.  **Construisez l'image :**
    ```sh
    docker build -t smartwatch .
    ```

2.  **Ex√©cutez le conteneur :**
    Assurez-vous que votre fichier `.env` est pr√©sent √† la racine.
    ```sh
    docker run --env-file .env -v $(pwd)/data:/app/data -v $(pwd)/logs:/app/logs smartwatch
    ```
    Les rapports et la base de donn√©es seront g√©n√©r√©s dans les dossiers `data` et `logs` de votre machine h√¥te.

## üìÑ Licence

Ce projet est sous licence GNU General Public License v3.0. Voir le fichier [LICENCE](LICENCE) pour
